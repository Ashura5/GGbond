{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dddf490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "directory = './top_300_metrics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74eacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects=[\"home-assistant/core\",\"NixOS/nixpkgs\",\"microsoft/vscode\",\"flutter/flutter\",\"MicrosoftDocs/azure-docs\",\"dotnet/runtime\",\"pytorch/pytorch\",\"odoo/odoo\",\"element-fi/elf-council-frontend\",\"godotengine/godot\",\"rust-lang/rust\",\"elastic/kibana\",\"archway-network/testnets\",\"kubernetes/kubernetes\",\"grafana/grafana\",\"microsoft/winget-pkgs\",\"microsoft/PowerToys\",\"solana-labs/token-list\",\"firstcontributions/first-contributions\",\"taozhiyu/TyProAction\",\"Homebrew/homebrew-core\",\"zephyrproject-rtos/zephyr\",\"dotnet/roslyn\",\"WordPress/gutenberg\",\"python/cpython\",\"elementor/elementor\",\"ClickHouse/ClickHouse\",\"mdn/content\",\"cypress-io/cypress\",\"AdguardTeam/AdguardFilters\",\"vercel/next.js\",\"expo/expo\",\"kubernetes/website\",\"PaddlePaddle/Paddle\",\"ray-project/ray\",\"apache/airflow\",\"mui/material-ui\",\"aws/aws-cdk\",\"ValveSoftware/Dota2-Gameplay\",\"huggingface/transformers\",\"google/it-cert-automation-practice\",\"openshift/openshift-docs\",\"DefinitelyTyped/DefinitelyTyped\",\"dotnet/aspnetcore\",\"tensorflow/tensorflow\",\"microsoft/vcpkg\",\"golang/go\",\"nodejs/node\",\"elastic/elasticsearch\",\"flutter/engine\",\"microsoft/playwright\",\"Automattic/wp-calypso\",\"airbytehq/airbyte\",\"dotnet/maui\",\"hashicorp/terraform-provider-azurerm\",\"Homebrew/homebrew-cask\",\"tgstation/tgstation\",\"webcompat/web-bugs\",\"microsoft/TypeScript\",\"Azure/azure-sdk-for-net\",\"microsoftgraph/microsoft-graph-docs\",\"hashicorp/terraform-provider-aws\",\"ant-design/ant-design\",\"CleverRaven/Cataclysm-DDA\",\"qmk/qmk_firmware\",\"pandas-dev/pandas\",\"yt-dlp/yt-dlp\",\"ShadowMario/FNF-PsychEngine\",\"Azure/azure-cli\",\"angular/angular\",\"quarkusio/quarkus\",\"facebook/react-native\",\"PrestaShop/PrestaShop\",\"Koenkk/zigbee2mqtt\",\"istio/istio\",\"apache/superset\",\"brave/brave-core\",\"nrwl/nx\",\"education/GitHubGraduation-2022\",\"conan-io/conan-center-index\",\"envoyproxy/envoy\",\"LeetCode-Feedback/LeetCode-Feedback\",\"nextcloud/server\",\"wjz304/Redpill_CustomBuild\",\"element-plus/element-plus\",\"ultralytics/yolov5\",\"getsentry/sentry\",\"Lightning-AI/lightning\",\"qgis/QGIS\",\"idsb3t1/KEEP-pipeline-tests-resources\",\"microsoft/onnxruntime\",\"Chia-Network/chia-blockchain\",\"prisma/prisma\",\"Azure/azure-rest-api-specs\",\"cockroachdb/cockroach\",\"strapi/strapi\",\"gitpod-io/gitpod\",\"llvm/llvm-project\",\"trinodb/trino\",\"systemd/systemd\",\"openjournals/joss-reviews\",\"openvinotoolkit/openvino\",\"go-gitea/gitea\",\"magento/magento2\",\"void-linux/void-packages\",\"openjdk/jdk\",\"TP-Lab/tokens\",\"microsoft/fluentui\",\"uBlockOrigin/uAssets\",\"gradle/gradle\",\"ceph/ceph\",\"symfony/symfony\",\"qbittorrent/qBittorrent\",\"trustwallet/assets\",\"apache/spark\",\"backstage/backstage\",\"gentoo/gentoo\",\"microsoft/terminal\",\"mui/mui-x\",\"Azure/azure-sdk-for-java\",\"woocommerce/woocommerce\",\"sourcegraph/sourcegraph\",\"Ultimaker/Cura\",\"neovim/neovim\",\"bitcoin/bitcoin\",\"metabase/metabase\",\"tachiyomiorg/tachiyomi-extensions\",\"joomla/joomla-cms\",\"dbeaver/dbeaver\",\"mdn/translated-content\",\"files-community/Files\",\"home-assistant/home-assistant.io\",\"mozilla-mobile/fenix\",\"Expensify/App\",\"openwrt/openwrt\",\"MicrosoftDocs/msteams-docs\",\"spack/spack\",\"nuxt/framework\",\"github/docs\",\"MetaMask/metamask-extension\",\"storybookjs/storybook\",\"spyder-ide/spyder\",\"electron/electron\",\"helium/denylist\",\"RocketChat/Rocket.Chat\",\"MicrosoftDocs/microsoft-365-docs\",\"project-chip/connectedhomeip\",\"vitejs/vite\",\"laravel/framework\",\"scikit-learn/scikit-learn\",\"keycloak/keycloak\",\"department-of-veterans-affairs/va.gov-team\",\"apache/shardingsphere\",\"containers/podman\",\"solana-labs/solana\",\"apache/arrow\",\"conda-forge/staged-recipes\",\"jlord/patchwork\",\"ccxt/ccxt\",\"sveltejs/kit\",\"apache/pulsar\",\"logseq/logseq\",\"apple/swift\",\"openssl/openssl\",\"renovatebot/renovate\",\"hashicorp/vault\",\"facebook/react\",\"bitnami/charts\",\"brave/brave-browser\",\"section-engineering-education/engineering-education\",\"microsoft/vscode-jupyter\",\"Azure/azure-sdk-for-python\",\"cms-sw/cmssw\",\"appsmithorg/appsmith\",\"AUTOMATIC1111/stable-diffusion-webui\",\"dotnet/docs\",\"JetBrains/swot\",\"openshift/release\",\"microsoft/WSL\",\"ValveSoftware/Proton\",\"apache/hudi\",\"rancher/rancher\",\"openhab/openhab-addons\",\"SerenityOS/serenity\",\"home-assistant/frontend\",\"pingcap/tidb\",\"metersphere/metersphere\",\"zulip/zulip\",\"JuliaLang/julia\",\"cilium/cilium\",\"dotnet/efcore\",\"JuliaRegistries/General\",\"PaddlePaddle/PaddleOCR\",\"argoproj/argo-cd\",\"RPCS3/rpcs3\",\"espressif/esp-idf\",\"apache/flink\",\"raycast/extensions\",\"tailscale/tailscale\",\"Azure/azure-powershell\",\"grpc/grpc\",\"nrfconnect/sdk-nrf\",\"microsoft/azuredatastudio\",\"MetaMask/eth-phishing-detect\",\"scipy/scipy\",\"directus/directus\",\"demisto/content\",\"ArduPilot/ardupilot\",\"MarlinFirmware/Marlin\",\"rails/rails\",\"ppy/osu\",\"aws-amplify/amplify-cli\",\"JacksonKearl/testissues\",\"desktop/desktop\",\"ankidroid/Anki-Android\",\"Azure/azure-sdk-for-js\",\"bioconda/bioconda-recipes\",\"bevyengine/bevy\",\"apache/beam\",\"open-telemetry/opentelemetry-collector-contrib\",\"leanprover-community/mathlib\",\"remix-run/remix\",\"github/codeql\",\"OpenAPITools/openapi-generator\",\"obsproject/obs-studio\",\"DataDog/datadog-agent\",\"ethereum/ethereum-org-website\",\"cloudflare/cloudflare-docs\",\"grafana/loki\",\"apache/iceberg\",\"gatsbyjs/gatsby\",\"gravitational/teleport\",\"darktable-org/darktable\",\"apache/tvm\",\"open-mmlab/mmdetection\",\"azerothcore/azerothcore-wotlk\",\"TeamNewPipe/NewPipe\",\"denoland/deno\",\"apache/dolphinscheduler\",\"matplotlib/matplotlib\",\"type-challenges/type-challenges\",\"postmanlabs/postman-app-support\",\"google-test/signclav2-probe-repo\",\"matrix-org/synapse\",\"firebase/flutterfire\",\"xamarin/xamarin-macios\",\"opencv/opencv\",\"flathub/flathub\",\"vectordotdev/vector\",\"taosdata/TDengine\",\"ruffle-rs/ruffle\",\"termux/termux-packages\",\"Automattic/jetpack\",\"dotnet/AspNetCore.Docs\",\"freddier/hyperblog\",\"oppia/oppia\",\"Skyrat-SS13/Skyrat-tg\",\"macports/macports-ports\",\"Kaiserreich/Kaiserreich-4\",\"apache/doris\",\"flutter/plugins\",\"rapid7/metasploit-framework\",\"xbmc/xbmc\",\"jitsi/jitsi-meet\",\"PixelExperience/android-issues\",\"ziglang/zig\",\"firebase/firebase-android-sdk\",\"mastodon/mastodon\",\"PowerShell/PowerShell\",\"docker/docs\",\"coolsnowwolf/lede\",\"prusa3d/PrusaSlicer\",\"redis/redis\",\"zero-to-mastery/start-here-guidelines\",\"ansible/ansible\",\"tachiyomiorg/tachiyomi\",\"alibaba/nacos\",\"newrelic/docs-website\",\"kubernetes/minikube\",\"yuzu-emu/yuzu\",\"o3de/o3de\",\"kubernetes/test-infra\",\"GoogleChrome/developer.chrome.com\",\"lensapp/lens\",\"filecoin-project/filecoin-plus-large-datasets\",\"Regalis11/Barotrauma\",\"rstudio/rstudio\",\"mlflow/mlflow\",\"angular/components\",\"kubevirt/kubevirt\",\"nextcloud/desktop\",\"apache/apisix\",\"IntelRealSense/librealsense\",\"mrdoob/three.js\",\"flybywiresim/a32nx\",\"helix-editor/helix\",\"php/php-src\",\"unifyai/ivy\",\"influxdata/telegraf\",\"mattermost/mattermost-webapp\"]\n",
    "# class_1=[\"activity.json\",\"attention.json\",\"bus_factor.json\",\"change_requests.json\",\"change_requests_reviews.json\",\"code_change_lines_add.json\",\"code_change_lines_remove.json\",\"code_change_lines_sum.json\",\"inactive_contributors.json\",\"issue_comments.json\",\"issues_and_change_request_active.json\",\"issues_closed.json\",\"issues_new.json\",\"new_contributors.json\",\"openrank.json\",\"participants.json\",\"stars.json\",\"technical_fork.json\"]\n",
    "# class_2=[\"change_request_age.json\",\"change_request_resolution_duration.json\",\"change_request_response_time.json\",\"issue_age.json\",\"issue_resolution_duration.json\",\"issue_response_time.json\"]\n",
    "class_1=[\"bus_factor.json\",\"change_requests.json\",\"change_requests_reviews.json\",\"code_change_lines_add.json\",\"code_change_lines_remove.json\",\"code_change_lines_sum.json\",\"inactive_contributors.json\",\"issues_and_change_request_active.json\",\"issues_closed.json\",\"issues_new.json\",\"new_contributors.json\",\"openrank.json\",\"technical_fork.json\"]\n",
    "class_2=[\"change_request_age.json\",\"change_request_resolution_duration.json\",\"change_request_response_time.json\",\"issue_age.json\",\"issue_resolution_duration.json\",\"issue_response_time.json\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c59679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_1(directory,project,file):\n",
    "    if not os.path.exists(os.path.join(directory+project, file)):\n",
    "        return pd.DataFrame()\n",
    "    with open(os.path.join(directory+project, file), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        if len(data)==0:\n",
    "             return pd.DataFrame()\n",
    "        temp_df = pd.DataFrame.from_dict(data, orient='index')\n",
    "        temp_df.columns = [file[:-5]]\n",
    "    return temp_df\n",
    "def process_2(directory,project,file):\n",
    "    df=pd.DataFrame()\n",
    "    if not os.path.exists(os.path.join(directory+project, file)):\n",
    "        return pd.DataFrame()\n",
    "    with open(os.path.join(directory+project, file), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for key in data:\n",
    "            if len(data[key])==0:\n",
    "                continue\n",
    "            temp_df = pd.DataFrame.from_dict(data[key], orient='index')\n",
    "            if key==\"levels\":\n",
    "                temp_df.columns = [str(file[:-5])+\"_\"+key+\"_0\",str(file[:-5])+\"_\"+key+\"_1\",str(file[:-5])+\"_\"+key+\"_2\",str(file[:-5])+\"_\"+key+\"_3\"]\n",
    "            else:\n",
    "                temp_df.columns = [str(file[:-5])+\"_\"+key]\n",
    "            if df.empty:\n",
    "                df = temp_df\n",
    "            else:\n",
    "                df = df.join(temp_df, how='outer')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f31f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "for project in projects:\n",
    "    df = pd.DataFrame()\n",
    "    for file in class_1:\n",
    "        temp_df=process_1(directory,project,file)\n",
    "        if df.empty:\n",
    "            df = temp_df\n",
    "        else:\n",
    "            df = df.join(temp_df, how='outer')\n",
    "    for file in class_2:\n",
    "        temp_df=process_2(directory,project,file)\n",
    "        if df.empty:\n",
    "            df = temp_df\n",
    "        else:\n",
    "            df = df.join(temp_df, how='outer')\n",
    "    if df.shape[0]>12:\n",
    "        df_list.append(df.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48075d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 9800.088331636534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 将所有的 DataFrame 合并为一个\n",
    "df_all = pd.concat(df_list)\n",
    "\n",
    "# 删除具有特定索引的行\n",
    "df_all = df_all.drop('2021-10-raw', errors='ignore')\n",
    "\n",
    "# 将日期转换为特征\n",
    "df_all.index = pd.to_datetime(df_all.index, errors='coerce')\n",
    "df_all['year'] = df_all.index.year\n",
    "df_all['month'] = df_all.index.month\n",
    "\n",
    "# 将数据分为特征和目标变量\n",
    "X_all = df_all.drop('openrank', axis=1)\n",
    "y_all = df_all['openrank']\n",
    "\n",
    "# 将数据分为训练集和测试集\n",
    "# 在这个例子中，我们使用2015年到2022年的数据作为训练集，2023年的数据作为测试集\n",
    "X_train_all = X_all[X_all['year'] < 2023]\n",
    "y_train_all = y_all[X_all['year'] < 2023]\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X_train_all = imputer.fit_transform(X_train_all)\n",
    "\n",
    "# 创建并训练一个 XGBoost 模型\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# 在训练数据上拟合模型\n",
    "rf_model.fit(X_train_all, y_train_all)\n",
    "\n",
    "\n",
    "# 初始化一个列表来存储每个项目的均方误差\n",
    "mse_list = []\n",
    "\n",
    "# 获取所有可能的特征\n",
    "all_features = df_all.columns\n",
    "\n",
    "# 对每个 DataFrame 单独进行预测\n",
    "for df in df_list:\n",
    "    # 删除具有特定索引的行\n",
    "    df = df.drop('2021-10-raw', errors='ignore')\n",
    "\n",
    "    # 将日期转换为特征\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    # 确保 DataFrame 包含所有可能的特征\n",
    "    for feature in all_features:\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = 0\n",
    "\n",
    "    # 确保特征的顺序与训练数据一致\n",
    "    df = df[all_features]\n",
    "\n",
    "    # 将数据分为特征和目标变量\n",
    "    X = df.drop('openrank', axis=1)\n",
    "    y = df['openrank']\n",
    "\n",
    "    # 选择2023年的数据作为测试集\n",
    "    X_test = X[X['year'] == 2023]\n",
    "    y_test = y[X['year'] == 2023]\n",
    "    X_test = imputer.transform(X_test)\n",
    "    # 在测试集上进行预测\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # 计算并存储均方误差\n",
    "    mse = mean_squared_error(y_test, rf_pred)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "# 计算并打印平均均方误差\n",
    "mean_mse = np.mean(mse_list)\n",
    "print(f'Mean Squared Error: {mean_mse}')\n",
    "# 输出特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f34643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "issues_and_change_request_active: 0.72565\n",
      "bus_factor: 0.10606\n",
      "technical_fork: 0.07172\n",
      "change_request_resolution_duration_levels_3: 0.03049\n",
      "change_requests_reviews: 0.01791\n",
      "inactive_contributors: 0.00627\n",
      "issue_age_quantile_4: 0.00371\n",
      "issue_age_levels_2: 0.00344\n",
      "change_requests: 0.00332\n",
      "change_request_age_quantile_1: 0.00299\n",
      "issue_age_levels_3: 0.00280\n",
      "issue_resolution_duration_levels_1: 0.00274\n",
      "issue_resolution_duration_levels_0: 0.00262\n",
      "change_request_age_levels_3: 0.00237\n",
      "year: 0.00214\n",
      "issues_closed: 0.00188\n",
      "change_request_resolution_duration_avg: 0.00181\n",
      "issue_response_time_levels_0: 0.00129\n",
      "change_request_resolution_duration_levels_2: 0.00112\n",
      "issue_response_time_levels_1: 0.00095\n",
      "change_request_age_avg: 0.00075\n",
      "issues_new: 0.00072\n",
      "change_request_age_quantile_2: 0.00059\n",
      "change_request_age_quantile_4: 0.00045\n",
      "change_request_resolution_duration_levels_0: 0.00043\n",
      "issue_age_quantile_3: 0.00043\n",
      "issue_age_quantile_2: 0.00041\n",
      "change_request_response_time_levels_0: 0.00039\n",
      "issue_resolution_duration_quantile_3: 0.00039\n",
      "issue_resolution_duration_levels_3: 0.00037\n",
      "change_request_resolution_duration_levels_1: 0.00037\n",
      "change_request_response_time_levels_1: 0.00036\n",
      "change_request_age_quantile_3: 0.00033\n",
      "issue_age_levels_1: 0.00029\n",
      "issue_age_avg: 0.00027\n",
      "issue_response_time_levels_3: 0.00024\n",
      "change_request_age_levels_0: 0.00021\n",
      "issue_age_quantile_0: 0.00021\n",
      "change_request_age_quantile_0: 0.00018\n",
      "change_request_age_levels_1: 0.00017\n",
      "issue_response_time_quantile_2: 0.00013\n",
      "new_contributors: 0.00013\n",
      "issue_response_time_quantile_3: 0.00012\n",
      "issue_resolution_duration_levels_2: 0.00010\n",
      "change_request_age_levels_2: 0.00009\n",
      "issue_response_time_quantile_1: 0.00008\n",
      "issue_resolution_duration_avg: 0.00007\n",
      "issue_resolution_duration_quantile_4: 0.00007\n",
      "issue_age_quantile_1: 0.00006\n",
      "change_request_resolution_duration_quantile_4: 0.00005\n",
      "change_request_resolution_duration_quantile_3: 0.00005\n",
      "code_change_lines_add: 0.00004\n",
      "issue_resolution_duration_quantile_2: 0.00004\n",
      "change_request_response_time_quantile_3: 0.00004\n",
      "issue_age_levels_0: 0.00003\n",
      "change_request_response_time_quantile_4: 0.00002\n",
      "issue_response_time_avg: 0.00002\n",
      "issue_response_time_quantile_4: 0.00002\n",
      "code_change_lines_remove: 0.00001\n",
      "code_change_lines_sum: 0.00001\n",
      "change_request_response_time_quantile_2: 0.00001\n",
      "month: 0.00001\n",
      "issue_resolution_duration_quantile_1: 0.00000\n",
      "issue_response_time_levels_2: 0.00000\n",
      "change_request_response_time_levels_2: 0.00000\n",
      "change_request_resolution_duration_quantile_0: 0.00000\n",
      "change_request_resolution_duration_quantile_1: 0.00000\n",
      "change_request_resolution_duration_quantile_2: 0.00000\n",
      "change_request_response_time_avg: 0.00000\n",
      "change_request_response_time_quantile_0: 0.00000\n",
      "change_request_response_time_quantile_1: 0.00000\n",
      "issue_resolution_duration_quantile_0: 0.00000\n",
      "issue_response_time_quantile_0: 0.00000\n",
      "change_request_response_time_levels_3: 0.00000\n"
     ]
    }
   ],
   "source": [
    "importances = rf_model.feature_importances_ \n",
    "\n",
    "feature_names = X_all.columns\n",
    "sorted_idx = np.argsort(importances)\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for i in sorted_idx[::-1]:\n",
    "    name = feature_names[i]\n",
    "    value = importances[i]\n",
    "    print(f\"{name}: {value:.5f}\")\n",
    "\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "top_features = list(feature_names[sorted_idx][:14])\n",
    "top_features.append('year')\n",
    "top_features.append('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db01063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 9798.08131014286\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat(df_list)\n",
    "\n",
    "# 删除具有特定索引的行\n",
    "df_all = df_all.drop('2021-10-raw', errors='ignore')\n",
    "\n",
    "# 将日期转换为特征\n",
    "df_all.index = pd.to_datetime(df_all.index, errors='coerce')\n",
    "df_all['year'] = df_all.index.year\n",
    "df_all['month'] = df_all.index.month\n",
    "\n",
    "# 将数据分为特征和目标变量\n",
    "X_all = df_all.drop('openrank', axis=1)\n",
    "y_all = df_all['openrank']\n",
    "X_all=X_all[top_features]\n",
    "# 将数据分为训练集和测试集\n",
    "# 在这个例子中，我们使用2015年到2022年的数据作为训练集，2023年的数据作为测试集\n",
    "X_train_all = X_all[X_all['year'] < 2023]\n",
    "y_train_all = y_all[X_all['year'] < 2023]\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X_train_all = imputer.fit_transform(X_train_all)\n",
    "\n",
    "# 创建并训练一个 XGBoost 模型\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# 在训练数据上拟合模型\n",
    "rf_model.fit(X_train_all, y_train_all)\n",
    "\n",
    "\n",
    "# 初始化一个列表来存储每个项目的均方误差\n",
    "mse_list = []\n",
    "\n",
    "# 获取所有可能的特征\n",
    "all_features = df_all.columns\n",
    "\n",
    "# 对每个 DataFrame 单独进行预测\n",
    "for df in df_list:\n",
    "    # 删除具有特定索引的行\n",
    "    df = df.drop('2021-10-raw', errors='ignore')\n",
    "\n",
    "    # 将日期转换为特征\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    # 确保 DataFrame 包含所有可能的特征\n",
    "    for feature in all_features:\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = 0\n",
    "\n",
    "    # 确保特征的顺序与训练数据一致\n",
    "    df = df[all_features]\n",
    "\n",
    "    # 将数据分为特征和目标变量\n",
    "    X = df.drop('openrank', axis=1)\n",
    "    y = df['openrank']\n",
    "    X = X[top_features]\n",
    "    # 选择2023年的数据作为测试集\n",
    "    X_test = X[X['year'] == 2023]\n",
    "    y_test = y[X['year'] == 2023]\n",
    "    X_test = imputer.transform(X_test)\n",
    "    # 在测试集上进行预测\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # 计算并存储均方误差\n",
    "    mse = mean_squared_error(y_test, rf_pred)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "# 计算并打印平均均方误差\n",
    "mean_mse = np.mean(mse_list)\n",
    "print(f'Mean Squared Error: {mean_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae3467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4723.578632308675\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 将所有的 DataFrame 合并为一个\n",
    "df_all = pd.concat(df_list)\n",
    "\n",
    "# 删除具有特定索引的行\n",
    "df_all = df_all.drop('2021-10-raw', errors='ignore')\n",
    "\n",
    "# 将日期转换为特征\n",
    "df_all.index = pd.to_datetime(df_all.index, errors='coerce')\n",
    "df_all['year'] = df_all.index.year\n",
    "df_all['month'] = df_all.index.month\n",
    "\n",
    "# 将数据分为特征和目标变量\n",
    "X_all = df_all.drop('openrank', axis=1)\n",
    "y_all = df_all['openrank']\n",
    "\n",
    "# 将数据分为训练集和测试集\n",
    "# 在这个例子中，我们使用2015年到2022年的数据作为训练集，2023年的数据作为测试集\n",
    "X_train_all = X_all[X_all['year'] < 2023]\n",
    "y_train_all = y_all[X_all['year'] < 2023]\n",
    "\n",
    "# 创建并训练一个 XGBoost 模型\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror', learning_rate = 0.1, max_depth = 5, n_estimators = 100)\n",
    "model.fit(X_train_all, y_train_all)\n",
    "\n",
    "# 初始化一个列表来存储每个项目的均方误差\n",
    "mse_list = []\n",
    "\n",
    "# 获取所有可能的特征\n",
    "all_features = df_all.columns\n",
    "\n",
    "# 对每个 DataFrame 单独进行预测\n",
    "for df in df_list:\n",
    "    # 删除具有特定索引的行\n",
    "    df = df.drop('2021-10-raw', errors='ignore')\n",
    "\n",
    "    # 将日期转换为特征\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    # 确保 DataFrame 包含所有可能的特征\n",
    "    for feature in all_features:\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = 0\n",
    "\n",
    "    # 确保特征的顺序与训练数据一致\n",
    "    df = df[all_features]\n",
    "\n",
    "    # 将数据分为特征和目标变量\n",
    "    X = df.drop('openrank', axis=1)\n",
    "    y = df['openrank']\n",
    "\n",
    "    # 选择2023年的数据作为测试集\n",
    "    X_test = X[X['year'] == 2023]\n",
    "    y_test = y[X['year'] == 2023]\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 计算并存储均方误差\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "# 计算并打印平均均方误差\n",
    "mean_mse = np.mean(mse_list)\n",
    "print(f'Mean Squared Error: {mean_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdb0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets, seq_length):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] - self.seq_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index:index+self.seq_length], self.targets[index+self.seq_length])\n",
    "\n",
    "# 初始化一个列表来存储每个项目的 Dataset 和 DataLoader\n",
    "datasets = []\n",
    "train_loaders = []\n",
    "val_loaders = []\n",
    "test_loaders = []\n",
    "\n",
    "# 对每个 DataFrame 单独进行处理\n",
    "for df in df_list:\n",
    "    # 删除具有特定索引的行\n",
    "    df = df.drop('2021-10-raw', errors='ignore')\n",
    "    for feature in all_features:\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = 0\n",
    "    # 将数据分为特征和目标变量\n",
    "    X = df.drop('openrank', axis=1).values\n",
    "    y = df['openrank'].values\n",
    "\n",
    "    # 根据时间划分数据集\n",
    "    train_data = df[df.index < '2022-10']\n",
    "    train_X=train_data.drop('openrank', axis=1).values\n",
    "    train_y=train_data['openrank'].values\n",
    "    val_data = df[(df.index >= '2022-04') & (df.index < '2023-01')]\n",
    "    val_X=val_data.drop('openrank', axis=1).values\n",
    "    val_y=val_data['openrank'].values\n",
    "    test_data = df[df.index >= '2022-07']\n",
    "    test_X=test_data.drop('openrank', axis=1).values\n",
    "    test_y=test_data['openrank'].values\n",
    "    # 创建 Dataset\n",
    "    train_dataset = MyDataset(train_X,train_y, seq_length=6)\n",
    "    val_dataset = MyDataset(val_X,val_y, seq_length=6)\n",
    "    test_dataset = MyDataset(test_X,test_y, seq_length=6)\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    train_loaders.append(train_loader)\n",
    "    val_loaders.append(val_loader)\n",
    "    test_loaders.append(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aed56c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 定义 LSTM 模型\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 初始化 LSTM 模型\n",
    "model = LSTM(input_size=74, hidden_size=50, num_layers=2, output_size=1)\n",
    "model = model.float().to(device)\n",
    "\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886e4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 15716.5107, Val MSE: 23807.5566\n",
      "Epoch [2/100], Loss: 12596.1143, Val MSE: 19906.4766\n",
      "Epoch [3/100], Loss: 10028.1650, Val MSE: 16617.3340\n",
      "Epoch [4/100], Loss: 7857.2393, Val MSE: 13759.0156\n",
      "Epoch [5/100], Loss: 6025.9268, Val MSE: 11267.3828\n",
      "Epoch [6/100], Loss: 4497.8667, Val MSE: 9103.5195\n",
      "Epoch [7/100], Loss: 3244.1672, Val MSE: 7237.3999\n",
      "Epoch [8/100], Loss: 2235.6694, Val MSE: 5636.8999\n",
      "Epoch [9/100], Loss: 1451.8514, Val MSE: 4281.4165\n",
      "Epoch [10/100], Loss: 870.8085, Val MSE: 3147.4688\n",
      "Epoch [11/100], Loss: 476.0927, Val MSE: 2221.5483\n",
      "Epoch [12/100], Loss: 248.2650, Val MSE: 1477.7347\n",
      "Epoch [13/100], Loss: 171.8260, Val MSE: 907.9250\n",
      "Epoch [14/100], Loss: 227.0967, Val MSE: 497.5143\n",
      "Epoch [15/100], Loss: 393.1590, Val MSE: 213.9123\n",
      "Epoch [16/100], Loss: 555.0704, Val MSE: 75.3190\n",
      "Epoch [17/100], Loss: 869.7682, Val MSE: 4.1390\n",
      "Epoch [18/100], Loss: 869.5592, Val MSE: 37.4775\n",
      "Epoch [19/100], Loss: 1213.0995, Val MSE: 5.7781\n",
      "Epoch [20/100], Loss: 1198.9572, Val MSE: 41.8269\n",
      "Validation MSE increased for 3 consecutive epochs. Training stopped.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 100\n",
    "best_val_mse = float('inf')  # 保存最佳验证集均方误差\n",
    "best_model_state_dict = None  # 保存最佳模型参数\n",
    "stop_count = 0  # 连续增加的计数器\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (train_loader, val_loader) in enumerate(zip(train_loaders, val_loaders)):\n",
    "        for data, targets in train_loader:\n",
    "            data = data.float().to(device)\n",
    "            targets = targets.float().unsqueeze(1).to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 在验证集上计算 MSE\n",
    "    val_predictions = []\n",
    "    val_targets = []\n",
    "    for data, targets in val_loader:\n",
    "        data = data.float().to(device)\n",
    "        targets = targets.float().unsqueeze(1).to(device)\n",
    "        outputs = model(data)\n",
    "        val_predictions.extend(outputs.detach().cpu().numpy())\n",
    "        val_targets.extend(targets.detach().cpu().numpy())\n",
    "    val_mse = mean_squared_error(val_targets, val_predictions)\n",
    "\n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}, Val MSE: {:.4f}' \n",
    "               .format(epoch+1, num_epochs, loss.item(), val_mse))\n",
    "        \n",
    "        # 检查是否连续增加\n",
    "    if val_mse < best_val_mse:\n",
    "        best_val_mse = val_mse\n",
    "        stop_count = 0\n",
    "            # 保存最佳模型参数\n",
    "        best_model_state_dict = model.state_dict()\n",
    "    else:\n",
    "        stop_count += 1\n",
    "        if stop_count >= 3:\n",
    "            print(\"Validation MSE increased for 3 consecutive epochs. Training stopped.\")\n",
    "            break\n",
    "    \n",
    "    if stop_count >= 3:\n",
    "        break\n",
    "\n",
    "# 返回在验证集上表现最好的模型参数\n",
    "model.load_state_dict(best_model_state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eee31ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './test_state_dict.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66959de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './test_state_dict.pth'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "129fe297",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "test_targets = []\n",
    "for data, targets in test_loader:\n",
    "    data = data.float().to(device)\n",
    "    targets = targets.float().unsqueeze(1).to(device)\n",
    "    outputs = model(data)\n",
    "    test_predictions.extend(outputs.detach().cpu().numpy())\n",
    "    test_targets.extend(targets.detach().cpu().numpy())\n",
    "test_mse = mean_squared_error(test_targets, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67b9a390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100.9384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cd8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
